{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4fa3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2900db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a9ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data quality & cleaning\n",
    "# DQ checks\n",
    "# Finding null values per column\n",
    "missing = pd.DataFrame({'Column':[],'Number of missing datapoints':[]})\n",
    "for i in range(len(titanic.columns)):\n",
    "    missing.loc[i,['Column']] = titanic.columns[i]\n",
    "    missing.loc[i,['Number of missing datapoints']] = titanic.iloc[:,i].isnull().sum()\n",
    "\n",
    "# look at the # of missing points in the first ten columns\n",
    "missing = missing.sort_values(by = ['Number of missing datapoints'],ascending = False)\n",
    "missing.reset_index(inplace = True, drop = True)\n",
    "missing\n",
    "# replace NA with mean imputation where possible\n",
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].mean())\n",
    "# generate dummy variable for sex\n",
    "titanic['Sex_dummy'] = np.where(titanic['Sex'].eq('female'),1,0)\n",
    "# separate dependent and independent variable which are usable\n",
    "y = titanic['Survived']\n",
    "X = titanic[['Pclass','Age','SibSp','Parch','Sex_dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38182980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c2b278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy base: 0.8208955223880597\n",
      "Accuracy ensemble: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "# Bagged Tree for the titanic dataset\n",
    "base = DecisionTreeClassifier(max_depth=5)\n",
    "ensemble = BaggingClassifier(base_estimator=base, n_estimators=100, random_state=7)\n",
    "\n",
    "base.fit(X_train,y_train)\n",
    "ensemble.fit(X_train,y_train)\n",
    "\n",
    "# Test accuracy (% of true positives and true negatives out of the total)\n",
    "print(\"Accuracy base:\",base.score(X_test, y_test))\n",
    "print(\"Accuracy ensemble:\",ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d291e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ensemble: 0.8208955223880597\n"
     ]
    }
   ],
   "source": [
    "# Random Forest for the titanic dataset\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=7)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Accuracy forest:\",forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83b97d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ensemble: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "# Boosted Tree\n",
    "boost = AdaBoostClassifier(base_estimator = base,n_estimators = 100, random_state = 7)\n",
    "boost.fit(X_train, y_train)\n",
    "print(\"Accuracy ensemble:\",boost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d048a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.383247\n",
       "4    0.332609\n",
       "0    0.154125\n",
       "2    0.076831\n",
       "3    0.053188\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine which of the features is the one that contributes the most to predicting whether a passenger survives or not.\n",
    "feature_importance = pd.Series(forest.feature_importances_).sort_values(ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08f3ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy base: 0.8432835820895522\n",
      "Accuracy forest: 0.8246268656716418\n"
     ]
    }
   ],
   "source": [
    "# Only 1st 3 features contribute a lot to the predicting passenger survival\n",
    "X2 = X.iloc[:,[1,4,0]]\n",
    "\n",
    "# retrain the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3, random_state= 4) # 70% training and 30% test\n",
    "base.fit(X_train,y_train)\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "print(\"Accuracy base:\",base.score(X_test, y_test))\n",
    "print(\"Accuracy forest:\",forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34fe269d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=7),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune the parameters n_estimators and max_depth.\n",
    "n_estimators = [int(i) for i in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_depth = [i for i in range(1,6)]\n",
    "param_dict = {'n_estimators': n_estimators, 'max_depth':max_depth}\n",
    "rf_grid = GridSearchCV(estimator = forest, param_grid = param_dict)\n",
    "rf_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2ac2f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 10}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the accuracy of all models and report which model performed the best, including the values for n_estimators and max_depth that the best model had\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5349e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832089552238806"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b15f38ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on training data with optimisted hyper-parameters is 0.8057784911717496.\n",
      "The score on testing data with optimisted hyper-parameters is 0.832089552238806.\n"
     ]
    }
   ],
   "source": [
    "# rerun models with these parameters\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=7,max_depth = 4)\n",
    "forest.fit(X_train,y_train)\n",
    "print(f\"The score on training data with optimisted hyper-parameters is {forest.score(X_train,y_train)}.\")\n",
    "print(f\"The score on testing data with optimisted hyper-parameters is {forest.score(X_test,y_test)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
